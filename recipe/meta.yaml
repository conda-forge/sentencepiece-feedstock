{% set version = "0.1.96" %}

package:
  name: sentencepiece-split
  version: {{ version }}

source:
  url: https://github.com/google/sentencepiece/archive/v{{ version }}.tar.gz
  sha256: 5198f31c3bb25e685e9e68355a3bf67a1db23c9e8bdccc33dc015f496a44df7a
  patches:
    # trying to build both static & shared build seems to break on OSX
    - patches/0001-do-not-mix-static-shared-builds.patch
    # use our own version of protobuf; for osx-arm, we cannot do that, as
    # calling protoc fails in cross-compilation due to the wrong CPU;
    # windows fails to build due in ways that have proven very hard to track down
    - patches/0002-do-not-build-protobuf-use-external-one.patch  # [not (win or build_platform != target_platform)]
    # without this patch, either linux gets $PREFIX/lib64
    # or CMAKE_INSTALL_LIBDIR won't work correctly
    - patches/0003-fix-libdir.patch

build:
  number: 0

requirements:
  build:
    - python                                 # [build_platform != target_platform]
    - cross-python_{{ target_platform }}     # [build_platform != target_platform]
    - cmake
    - {{ compiler('cxx') }}
  host:
    - abseil-cpp
    - libprotobuf

outputs:
  - name: libsentencepiece
    script: build-lib.sh   # [not win]
    script: build-lib.bat  # [win]
    build:
      run_exports:
        # not clear what ABI-compatibility of sentencepiece versions are;
        # for now, use same version at run & build time
        - libsentencepiece ={{ version }}
    requirements:
      build:
        - cmake
        - {{ compiler('cxx') }}
        - gperftools  # [unix]
        - make
        - pkg-config
      host:
        - abseil-cpp
        - libprotobuf

    test:
      commands:
        # binaries
        - spm_decode --help
        - spm_encode --help
        - spm_export_vocab --help
        - spm_normalize --help
        - spm_train --help
        # shared
        - test -f $PREFIX/lib/libsentencepiece.so.0                     # [linux]
        - test -f $PREFIX/lib/libsentencepiece_train.so.0               # [linux]
        - test -f $PREFIX/lib/libsentencepiece.0.dylib                  # [osx]
        - test -f $PREFIX/lib/libsentencepiece_train.0.dylib            # [osx]
        - if not exist %LIBRARY_BIN%\libsentencepiece.dll exit 1        # [win]
        - if not exist %LIBRARY_BIN%\libsentencepiece_train.dll exit 1  # [win]
        # absence of static libraries
        - test ! -f $PREFIX/lib/libsentencepiece.a                      # [not win]
        - test ! -f $PREFIX/lib/libsentencepiece_train.a                # [not win]
        # headers
        {% for each_header in ["sentencepiece_processor.h", "sentencepiece_trainer.h"] %}
        - test -f $PREFIX/include//{{ each_header }} || (echo "{{ each_header }} not found" && exit 1)  # [unix]
        - if not exist %LIBRARY_INC%\\{{ each_header }} exit 1                                          # [win]
        {% endfor %}

  - name: sentencepiece
    script: build-pkg.sh   # [not win]
    script: build-pkg.bat  # [win]
    requirements:
      build:
        - python                                 # [build_platform != target_platform]
        - cross-python_{{ target_platform }}     # [build_platform != target_platform]
        - {{ compiler('cxx') }}
        - pkg-config
      host:
        - python
        - pip
        - {{ pin_subpackage('libsentencepiece', exact=True) }}
      run:
        - python
        - {{ pin_subpackage('libsentencepiece', exact=True) }}
    test:
      imports:
        - sentencepiece
      requires:
        - pip
        - pytest
      source_files:
        - python/test
        - data
      commands:
        - pip check
        # upstream test suite expects to be run from PKG_ROOT/python
        - cd python && pytest test

about:
  home: "https://github.com/google/sentencepiece/"
  license: Apache-2.0
  license_family: Apache
  license_file: LICENSE
  summary: Unsupervised text tokenizer for Neural Network-based text generation.
  description: |
    SentencePiece is an unsupervised text tokenizer and detokenizer mainly for
    Neural Network-based text generation systems where the vocabulary size is
    predetermined prior to the neural model training.

    SentencePiece implements subword units (e.g., byte-pair-encoding (BPE)
    [[Sennrich et al.](http://www.aclweb.org/anthology/P16-1162)]) and unigram
    language model [[Kudo](https://arxiv.org/abs/1804.109590)]) with the
    extension of direct training from raw sentences. SentencePiece allows us to
    make a purely end-to-end system that does not depend on language-specific
    pre/postprocessing.

extra:
  recipe-maintainers:
    - setu4993
    - rluria14
    - ndmaxar
    - oblute
    - h-vetinari
  feedstock-name: sentencepiece
